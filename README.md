**This repository presents a unified workflowâ€”from raw XPT conversion through exploratory statistics to predictive modelingâ€”showing how pairing objective accelerometer measures with subjective surveys boosts healthâ€status classification performance.**

**ğŸ”„ Data Conversion & Documentation**

Source & Format: Started with NHANES XPT files and accompanying data dictionaries îˆ€citeîˆ‚turn0file0îˆ.

XPT â†’ CSV Pipeline: Developed a conversion script to batchâ€translate each XPT dataset into CSV, preserving variable labels and facilitating downstream analysis.

Dataset Selection: Chose three core sources for modeling:

day_data.csv: Daily aggregates of wear metrics (sleep, wake, MIMS sum)

subjective_data.csv: Questionnaire responses on work, recreation, walking, sedentary behavior

demo_data.csv: Demographics & medicalâ€consult indicators, including age, gender, income, education, and medical advice flags

**ğŸ” Exploratory Analysis & Aggregation**

Participantâ€Level Summaries: Grouped day_data by participant (SEQN), computing perâ€person mean/Ïƒ for key metrics across ~6â€¯917 individuals:

| Metric  | Header 2 | Header 3 |
| -------- | -------- | -------- |
| Row 1A   | Row 1B   | Row 1C   |
| Row 2A   | Row 2B   | Row 2C   |


**Wearâ€Time Patterns:**

First/Last Day: Partial data on daysâ€¯1 &â€¯9 (â‰ˆâ€¯500â€¯min), full wear (â‰ˆâ€¯1â€¯436â€¯min) on daysâ€¯2â€“8.

Weekday vs. Weekend: Nearly identical wear and QC flags; wake/sleep ratio ~2.05 both on weekdays and weekends.

Wake/Sleep by Day: Consistent 2:1 wake/sleep ratio across daysâ€¯2â€“8.

**Quantile Stratification:**

Binned PAXMTSD into Low/Medium/High tertiles and compared wake/sleep ratios:

Quantile

Mean Wake/Sleep

Ïƒ

Low

1.63

0.34

Medium

2.05

0.41

High

2.73

0.57

**Subjective vs. Objective:**

Weak correlations (|r|<0.11) between survey items and MIMS sum, highlighting reporting bias and the need for sensor data.

**Demographic Correlations:**

Age vs. MIMS: r=â€“0.21 (older â†’ less movement)

Income vs. MIMS: râ‰ˆ0.02 (no link)

Household size vs. MIMS: r=0.18 (larger households â†’ more movement)

Education/income: negligible effects

**ğŸ§ª Statistical Testing & Target Definition**

**ANOVA & Tukey HSD on fiveâ€level health status (HSD010) vs. continuous metrics:**

Significant separation between categoriesâ€¯1â€“3 (homogeneous cluster) andâ€¯4â€“5 (lowerâ€activity cluster).

Example: Î” MIMS sum between Excellent (1) and Poor (5) = â€“2â€¯002 units (pâ€‘adj<0.0001).

Binary Target Creation: Collapsed HSD010 into 0 = best health (1â€“3), 1 = worst health (4â€“5) based on statistical homogeneity and improved power.

**ğŸ““ Notebooks & Modeling**

**1. Data Preprocessing**

initial_work.ipynb: ETL of CSVs, variable pruning (selecting pa_level_activity, sleep_wear, wake_wear, selected demo/medical flags), dtype alignment, missingâ€value handling.

**2. Statsmodels Logistic Regression**

Framework: statsmodels.Logit pipelines for subjective, objective, and combined data, with full inference output (coefficients, zâ€‘scores, pâ€‘values, Pseudoâ€¯RÂ²).

**Key Findings:**

Combined model: Pseudoâ€¯RÂ²â€¯â‰ˆâ€¯0.175; objectiveâ€‘only: 0.119; subjectiveâ€‘only: 0.170.

Subjective features alone nearly match combined fit, underscoring survey power.

**3. scikitâ€‘learn Logistic Regression**

Mirror statsmodels setups using LogisticRegression + StandardScaler, singleâ€run and oversampled (Ã—10) evaluations, confirming consistent coefficient direction and metrics.

**4. Random Forest Classification**

sklearn.ensemble.RandomForestClassifier on three feature sets.

Imbalance Strategies: class weights, random oversampling, and threshold tuning (optimized for F1 on classâ€¯1).

Outcome: Combined feature RF (tuned) achieved best recall (~0.21) and F1 (~0.28) for â€œworst health,â€ demonstrating the synergy of subjective + objective inputs.

**ğŸš€ Key Insights**

Objective data alone excels at characterizing the majority (high precision) but misses most atâ€risk cases (low recall).

Subjective surveys boost recall for the atâ€risk class (â†‘â€¯18% vs. 12%) at minor precision cost.

Combined models deliver the best balance: highest AUC, recall, and F1 for critical binary classification.

Threshold tuning and class weighting are essential to improve minorityâ€class detection in healthâ€risk contexts.


